from typing import List
import json
import requests
import pandas as pd
import os
from dotenv import load_dotenv

from django.conf import settings

from langchain_openai import ChatOpenAI  # OpenAI language model integration with LangChain
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents.agent_types import AgentType
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent

from langgraph.graph import StateGraph, START, END,MessagesState
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import ToolNode
from langchain_core.tools import tool


# Define the state class
class State(MessagesState):
    pass


load_dotenv()

api_key = os.getenv("OPENAI_API_KEY")


df = pd.read_csv('../proyectos_construccion_dataset.csv', delimiter=',')

import io
import base64
################################################################
# HISTOGRAM TOOL
################################################################
import uuid

def save_image_to_file(base64_content, file_path=None):
    # Generar un nombre √∫nico para cada imagen
    if not file_path:
        unique_name = f"temp_image_{uuid.uuid4().hex}.png"
        file_path = unique_name
    
    # Ruta completa para guardar en la carpeta est√°tica
    full_path = os.path.join(settings.STATICFILES_DIRS[0], file_path)
    with open(full_path, "wb") as f:
        f.write(base64.b64decode(base64_content))
    # Devuelve la URL relativa
    return f"{settings.STATIC_URL}{file_path}"

@tool
def generate_histogram(column_name: str) -> str:
    """
    Genera un histograma de la columna especificada en el dataframe y retorna el path de la imagen codificada en base64.
    """
    import matplotlib
    import matplotlib.pyplot as plt
    matplotlib.use('Agg')

    print("Generating histogram for column:", column_name)
    try:
        plt.figure(figsize=(10, 6))
    except Exception as e:
        print("Error: ", e)
    print("Plotting histogram...")
    
    plt.hist(df[column_name].dropna(), bins=30, color='blue', alpha=0.7)
    plt.title(f'Histograma de {column_name}')
    plt.xlabel(column_name)
    plt.ylabel('Frecuencia')
    plt.grid(axis='y', alpha=0.75)
    print("Saving histogram...")
    buf = io.BytesIO()
    plt.savefig(buf, format='png')
    buf.seek(0)
    print("Encoding histogram image...")
    image_base64 = base64.b64encode(buf.read()).decode('utf-8')
    print("Histogram image encoded successfully.")
    
    img_path = save_image_to_file(image_base64)
    
    print("Image saved to: ", img_path)
    return img_path

################################################################
# CSV AGENT AS TOOL
################################################################

custom_suffix = """Instrucciones adicionales:
Las columnas del dataframe son: 
{dfcolumns}"""
custom_suffix = custom_suffix.format(dfcolumns=df.columns)

agent = create_pandas_dataframe_agent(
    ChatOpenAI(temperature=0, model="gpt-4o-mini", api_key=api_key),
    df,
    verbose=True,
    agent_type=AgentType.OPENAI_FUNCTIONS,
    allow_dangerous_code=True,
    suffix=custom_suffix,
    include_df_in_prompt=True,
)

csv_agent_as_tool = agent.as_tool(
    name="csv_agent",
    description="Agent for csv file",
)

################################################################
# Generate chart tool
################################################################


@tool
def generate_chart(chart_type: str, x_column: str, y_column: str = None) -> dict:
    """
    Genera gr√°ficos basados en el tipo solicitado (histograma, dispersi√≥n, l√≠neas, etc.) y las columnas especificadas.
    Retorna un diccionario con los datos para un gr√°fico interactivo.
    
    Par√°metros:
    - chart_type: Tipo de gr√°fico ('histogram', 'scatter', 'line', etc.).
    - x_column: Columna del eje X.
    - y_column: Columna del eje Y (opcional, para gr√°ficos como dispersi√≥n o l√≠neas).
    """
    import matplotlib.pyplot as plt
    import numpy as np

    print(f"Generating {chart_type} for columns: {x_column} {f'vs {y_column}' if y_column else ''}")

    if x_column not in df.columns or (y_column and y_column not in df.columns):
        return {"error": f"Las columnas especificadas no existen: {x_column}, {y_column}"}

    chart_data = {}

    if chart_type == "histogram":
        data = df[x_column].dropna()
        counts, bins = np.histogram(data, bins=30)
        chart_data = {
            "x": bins[:-1].tolist(),
            "y": counts.tolist(),
            "type": "bar",
            "name": f"Histograma de {x_column}"
        }

    elif chart_type == "scatter":
        if y_column is None:
            return {"error": "Se requiere una columna Y para gr√°ficos de dispersi√≥n."}
        x_data = df[x_column].dropna()
        y_data = df[y_column].dropna()
        chart_data = {
            "x": x_data.tolist(),
            "y": y_data.tolist(),
            "type": "scatter",
            "mode": "markers",
            "name": f"{x_column} vs {y_column}"
        }

    elif chart_type == "line":
        if y_column is None:
            return {"error": "Se requiere una columna Y para gr√°ficos de l√≠neas."}
        x_data = df[x_column].dropna()
        y_data = df[y_column].dropna()
        chart_data = {
            "x": x_data.tolist(),
            "y": y_data.tolist(),
            "type": "line",
            "name": f"{x_column} vs {y_column}"
        }

    elif chart_type == "box":
        if y_column is None:
            return {"error": "Se requiere una columna Y para gr√°ficos de caja."}
        x_data = df[x_column].dropna()
        y_data = df[y_column].dropna()
        chart_data = {
            "x": x_data.tolist(),
            "y": y_data.tolist(),
            "type": "box",
            "name": f"{x_column} vs {y_column}"
        }
        
    elif chart_type == "bar":
        if y_column is None:
            return {"error": "Se requiere una columna Y para gr√°ficos de barras."}
        x_data = df[x_column].dropna()
        y_data = df[y_column].dropna()
        chart_data = {
            "x": x_data.tolist(),
            "y": y_data.tolist(),
            "type": "bar",
            "name": f"{x_column} vs {y_column}"
        }
        
    else:
        return {"error": f"Tipo de gr√°fico no soportado: {chart_type}"}

    print(f"{chart_type} data generated successfully.")
    return {"chart_data": chart_data, "title": f"{chart_type.capitalize()} de {x_column} {f'vs {y_column}' if y_column else ''}"}


################################################################
# PREDICT PRESUPUESTO REAL API
################################################################

# @tool
# def api_predict(features) -> float:
#     """
#     Chat function that makes an API call to a moodel to predict a response.
#     Las features son:
#     - feature_1: presupuesto_adjudicacion
#     - feature_2: plazo_entrega_real
#     - feature_3: plazo_entrega_adjudicacion
#     """
#     print("API FEATURES: ", features)
#     url = "http://localhost:8000/predict/"

#     payload = {"features": features}
#     payload_str = json.dumps(payload, indent=4)
#     headers = {
#         "Content-Type": "application/json",
#         "User-Agent": "insomnia/10.1.1",
#         "Authorization": "Token d20eaaba74be7fe262fa6a997da0b6bd29091031"
#     }

#     response = requests.request("POST", url, data=payload_str, headers=headers)

#     print(response.text)
    
#     return response.json()["prediction"]


# # Initialize the language model with the specified model name
# llm = ChatOpenAI(model="gpt-4o-mini", api_key=settings.OPENAI_API_KEY)

# tools = [api_predict, csv_agent_as_tool, generate_chart]
HEADERS = {
    "Content-Type": "application/json",
    "User-Agent": "LangChain-Predictor",
    "Authorization": f"Token d20eaaba74be7fe262fa6a997da0b6bd29091031"
}
BASE_URL = "http://localhost:8000/predict/"  # Base URL para las predicciones

# ========================== 1Ô∏è‚É£ PREDICCI√ìN DEL COSTO FINAL ==========================
@tool
def api_predict_costo_final(features) -> float:
    """
    Predice el Costo Final de un proyecto de construcci√≥n.
    """
    print("API FEATURES: ", features)
    print("API FEATURES: ")
    url = f"{BASE_URL}costo_final/"
    return call_prediction_api(url, features)

# ========================== 2Ô∏è‚É£ PREDICCI√ìN DE DURACI√ìN REAL ==========================
@tool
def api_predict_duracion_real(features) -> float:
    """
    Predice la Duraci√≥n Real de un proyecto de construcci√≥n.
    """
    print("API FEATURES: ", features)
    url = f"{BASE_URL}duracion_real/"
    return call_prediction_api(url, features)

# ========================== 3Ô∏è‚É£ PREDICCI√ìN DE SATISFACCI√ìN DEL CLIENTE ==========================
@tool
def api_predict_satisfaccion_cliente(features) -> float:
    """
    Predice la Satisfacci√≥n del Cliente en un proyecto de construcci√≥n.
    """
    url = f"{BASE_URL}satisfaccion_cliente/"
    return call_prediction_api(url, features)

# ========================== 4Ô∏è‚É£ PREDICCI√ìN DE DESVIACI√ìN PRESUPUESTARIA ==========================
@tool
def api_predict_desviacion_presupuestaria(features) -> float:
    """
    Predice la Desviaci√≥n Presupuestaria en un proyecto de construcci√≥n.
    """
    url = f"{BASE_URL}desviacion_presupuestaria/"
    return call_prediction_api(url, features)

# ========================== FUNCI√ìN AUXILIAR PARA LLAMAR A LA API ==========================
def call_prediction_api(url, features):
    """
    Realiza la llamada a la API de predicci√≥n y maneja errores.
    """
    print(f"üîç Enviando solicitud a {url} con features: {features}")

    payload = {"features": features}

    try:
        response = requests.post(url, json=payload, headers=HEADERS)
        response_data = response.json()

        if response.status_code == 200:
            print(f"‚úÖ Predicci√≥n recibida: {response_data}")
            return response_data
        else:
            print(f"‚ö†Ô∏è Error en la API ({response.status_code}): {response_data}")
            return {"error": f"API Error ({response.status_code}): {response_data}"}

    except requests.exceptions.RequestException as e:
        print(f"üö® Fallo en la conexi√≥n con la API: {str(e)}")
        return {"error": f"Fallo en la conexi√≥n con la API: {str(e)}"}
    
# # Initialize the language model with the specified model name
llm = ChatOpenAI(model="gpt-4o-mini", api_key=settings.OPENAI_API_KEY)

tools = [api_predict_costo_final, api_predict_duracion_real, api_predict_satisfaccion_cliente, api_predict_desviacion_presupuestaria, call_prediction_api, csv_agent_as_tool, generate_chart]


################################################################
# CHAT NODE
################################################################

def chat(state: State):
    """
    Chat function that takes a state object as input and returns a response.
    """
    system = """Eres un asistente virtual especializado en la gesti√≥n de proyectos de construcci√≥n. 
Tu prop√≥sito principal es ofrecer soporte inteligente a una empresa mediante la consulta de datos hist√≥ricos de obras ejecutadas, la estimaci√≥n de riesgos y desviaciones en presupuestos, y la recomendaci√≥n de estrategias para optimizar la planificaci√≥n y minimizar riesgos.
Los datos se encuentran en el archivo: o2.csv.

Dispones de una serie de funciones que puedes utilizar para resolver ciertas tareas:
Herramientas del Asistente:
    1- Prediccion de presupuesto real: utiliza la funcion api_predict para predecir el presupuesto real de un proyecto. Debes pasarle una lista de features con los valores correspondientes.
    Las features son:
        - feature_1: presupuesto_adjudicacion
        - feature_2: plazo_entrega_real
        - feature_3: plazo_entrega_adjudicacion
        Return: [presupuesto_adjudicacion, plazo_entrega_real, plazo_entrega_adjudicacion] (eje: [1000000, 12, 10])
 
    2- csv_agent: agente para interactuar con un archivo csv. Puedes utilizarlo para realizar consultas.
    3- generate_chart: funci√≥n que genera un gr√°fico interactivo basado en los datos del archivo csv. 
    
 Interacci√≥n:
	1.	Entrada del Usuario:
        ‚Ä¢	El usuario puede:
        ‚Ä¢	Describir una necesidad o plantear preguntas como:
        ‚Ä¢	‚Äú¬øQu√© desviaciones puedo esperar para un proyecto de construcci√≥n de viviendas con $500,000 en Madrid?‚Äù
        ‚Ä¢	‚ÄúMu√©strame obras similares ejecutadas el √∫ltimo a√±o.‚Äù
        ‚Ä¢	Usar un formulario guiado para introducir datos de un nuevo proyecto.
	2.	Salida del Asistente:
        ‚Ä¢	Ofrece respuestas en formatos como:
        ‚Ä¢	Texto explicativo.
        ‚Ä¢	Gr√°ficos interactivos.
        ‚Ä¢	Tablas comparativas.
        ‚Ä¢	Proporciona siempre una justificaci√≥n clara basada en datos y predicciones.
    3. Si el ultimo mensaje es un ToolMessage donde hay una imagen codificada en base64, el devolver√° la imagen.
 
 Formato de Respuesta Esperado:
	‚Ä¢	Comienza con un resumen de la consulta del usuario.
	‚Ä¢	Presenta la informaci√≥n m√°s relevante y estructurada:
	‚Ä¢	Si es una consulta hist√≥rica, ofrece datos organizados y filtrados.
	‚Ä¢	Si es una predicci√≥n, incluye porcentajes de riesgo y gr√°ficos.
	‚Ä¢	Si son recomendaciones, sugiere pasos espec√≠ficos y justifica con datos.
	‚Ä¢	Cierra ofreciendo ayuda adicional o aclaraciones si es necesario.
 
 Instrucciones al Asistente:
	‚Ä¢	Mant√©n un tono profesional, preciso y accesible.
	‚Ä¢	Si la consulta no es clara, solicita educadamente informaci√≥n adicional.
	‚Ä¢	Garantiza que las visualizaciones sean claras y f√°ciles de entender.
	‚Ä¢	Respeta la confidencialidad y privacidad de los datos.
 
 Ejemplo de Solicitud:
	‚Äú¬øQu√© riesgos puedo prever para un proyecto de infraestructura vial con un presupuesto de $1,000,000 en Barcelona con un plazo estimado de 12 meses?‚Äù
	Respuesta esperada:
        ‚Ä¢	Porcentaje de desviaci√≥n estimada en costos y tiempos.
        ‚Ä¢	Factores de riesgo espec√≠ficos basados en datos hist√≥ricos.
        ‚Ä¢	Recomendaciones para mitigar los riesgos.
 """
           
    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system),
            MessagesPlaceholder(variable_name="messages"),
        ]
    )
    
    chain = prompt | llm.bind_tools(tools)
    
    print("--------- ENTERTING CHAT NODE ---------")
    #print("Messages received: ", state["messages"])
    print("--------- ------------------ ---------")
    
    # Get 2 last messages
    last_messages = state["messages"]
    # Generate a response using the language model
    response = chain.invoke({"messages": last_messages})
    
    print("Response: ", response)
    # Return the response to the user
    return {"messages":response}


################################################################
# GRAPH
################################################################

def need_tool(state: State):
    messages = state["messages"]
    last_message = messages[-1]
    #print("last_message: ", last_message, "\n\n")
    # If there is no function call, then we respond to the user
    if last_message.tool_calls:
        print("Tool call detected.")
        return "tool"
    else:
        print("No tool call detected.")
        return "end"
    
graph = StateGraph(State)
graph.add_node("chat", chat)
graph.add_node("tool", ToolNode(tools))
graph.add_edge(START, "chat")
graph.add_conditional_edges(
    "chat",
    need_tool,
    {
        "tool": "tool",
        "end": END,
    },
)
graph.add_edge("tool", "chat")
config = {"configurable": {"thread_id": "user_id"}}
memory = MemorySaver()
app = graph.compile(checkpointer=memory)

################################################################